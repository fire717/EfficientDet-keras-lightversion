#coding: utf-8"""Copyright 2017-2018 Fizyr (https://fizyr.com)Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at    http://www.apache.org/licenses/LICENSE-2.0Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License."""import argparsefrom datetime import dateimport osimport sysimport tensorflow as tffrom tensorflow import kerasimport tensorflow.keras.backend as Kfrom tensorflow.keras.optimizers import Adam, SGDimport randomimport numpy as npimport cv2from PIL import Image, ImageEnhance, ImageOps#from augmentor.color import VisualEffect#from augmentor.misc import MiscEffectfrom utils import reorder_vertexesfrom model import efficientdetfrom losses import smooth_l1, focal, smooth_l1_quadfrom efficientnet import BASE_WEIGHTS_PATH, WEIGHTS_HASHESfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateaurandom.seed(42)np.random.seed(42)################## params ########################################################################## utils ################################################################## augmentor transform #################################identity_matrix = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])def colvec(*args):    """    Create a numpy array representing a column vector.    """    return np.array([args]).Tdef transform_aabb(transform_matrix, aabb):    """    Apply a transformation to an axis aligned bounding box.    The result is a new AABB in the same coordinate system as the original AABB.    The new AABB contains all corner points of the original AABB after applying the given transformation.    Args        transform: The transformation to apply.        x1: The minimum x value of the AABB.        y1: The minimum y value of the AABB.        x2: The maximum x value of the AABB.        y2: The maximum y value of the AABB.    Returns        The new AABB as tuple (x1, y1, x2, y2)    """    x1, y1, x2, y2 = aabb    # Transform all 4 corners of the AABB.    points = transform_matrix.dot([        [x1, x2, x1, x2],        [y1, y2, y2, y1],        [1, 1, 1, 1],    ])    # Extract the min and max corners again.    # (3, ) (min_x, min_y, 1)    min_corner = points.min(axis=1)    # (3, ) (max_x, max_y, 1)    max_corner = points.max(axis=1)    return [min_corner[0], min_corner[1], max_corner[0], max_corner[1]]def random_value(min, max):    return np.random.uniform(min, max)def random_vector(min, max):    """    Construct a random vector between min and max.    Args        min: the minimum value for each component, (n, )        max: the maximum value for each component, (n, )    """    min = np.array(min)    max = np.array(max)    assert min.shape == max.shape    assert len(min.shape) == 1    return np.random.uniform(min, max)def rotation(min=0, max=0, prob=0.5):    """    Construct a homogeneous 2D rotation matrix.    Args        min: a scalar for the minimum absolute angle in radians        max: a scalar for the maximum absolute angle in radians    Returns        the rotation matrix as 3 by 3 numpy array    """    random_prob = np.random.uniform()    if random_prob > prob:        # angle: the angle in radians        angle = random_value(min=min, max=max)        return np.array([            [np.cos(angle), -np.sin(angle), 0],            [np.sin(angle), np.cos(angle), 0],            [0, 0, 1]        ])    else:        return identity_matrixdef translation_x(min=0, max=0, prob=0.5):    """    Construct a homogeneous 2D translation matrix.    Args:        min: a scalar for the minimum translation for x axis        max: a scalar for the maximum translation for x axis    Returns:        the translation matrix as 3 by 3 numpy array    """    random_prob = np.random.uniform()    if random_prob > prob:        # translation: the translation 2D vector        translation = random_value(min=min, max=max)        return np.array([            [1, 0, translation],            [0, 1, ],            [0, 0, 1]        ])    else:        return identity_matrixdef translation_y(min=0, max=0, prob=0.5):    """    Construct a homogeneous 2D translation matrix.    Args:        min: a scalar for the minimum translation for y axis        max: a scalar for the maximum translation for y axis    Returns:        the translation matrix as 3 by 3 numpy array    """    random_prob = np.random.uniform()    if random_prob > prob:        # translation: the translation 2D vector        translation = random_value(min=min, max=max)        return np.array([            [1, 0],            [0, 1, translation],            [0, 0, 1]        ])    else:        return identity_matrixdef translation_xy(min=(0, 0), max=(0, 0), prob=0.5):    """    Construct a homogeneous 2D translation matrix.    Args:        min: a scalar for the minimum translation for y axis        max: a scalar for the maximum translation for y axis    Returns:        the translation matrix as 3 by 3 numpy array    """    random_prob = np.random.uniform()    if random_prob < prob:        # translation: the translation 2D vector        dx = np.random.randint(min[0], max[0])        dy = np.random.randint(min[1], max[1])        return np.array([            [1, 0, dx],            [0, 1, dy],            [0, 0, 1]        ])    else:        return identity_matrixdef shear_x(min=0, max=0, prob=0.5):    """    Construct a homogeneous 2D shear matrix.    Args        min:  the minimum shear angle in radians.        max:  the maximum shear angle in radians.    Returns        the shear matrix as 3 by 3 numpy array    """    random_prob = np.random.uniform()    if random_prob > prob:        # angle: the shear angle in radians        angle = random_value(min=min, max=max)        return np.array([            [1, np.tan(angle), 0],            [0, 1, 0],            [0, 0, 1]        ])    else:        return identity_matrixdef shear_y(min, max, prob=0.5):    """    Construct a homogeneous 2D shear matrix.    Args        min:  the minimum shear angle in radians.        max:  the maximum shear angle in radians.    Returns        the shear matrix as 3 by 3 numpy array    """    random_prob = np.random.uniform()    if random_prob > prob:        # angle: the shear angle in radians        angle = random_value(min=min, max=max)        return np.array([            [1, 0, 0],            [np.tan(angle), 1, 0],            [0, 0, 1]        ])    else:        return identity_matrixdef scaling_x(min=0.9, max=1.1, prob=0.5):    """    Construct a homogeneous 2D scaling matrix.    Args        factor: a 2D vector for X and Y scaling    Returns        the zoom matrix as 3 by 3 numpy array    """    random_prob = np.random.uniform()    if random_prob > prob:        # angle: the shear angle in radians        factor = random_value(min=min, max=max)        return np.array([            [factor, 0, 0],            [0, 1, 0],            [0, 0, 1]        ])    else:        return identity_matrixdef scaling_y(min=0.9, max=1.1, prob=0.5):    """    Construct a homogeneous 2D scaling matrix.    Args        factor: a 2D vector for X and Y scaling    Returns        the zoom matrix as 3 by 3 numpy array    """    random_prob = np.random.uniform()    if random_prob > prob:        # angle: the shear angle in radians        factor = random_value(min=min, max=max)        return np.array([            [1, 0, 0],            [0, factor, 0],            [0, 0, 1]        ])    else:        return identity_matrixdef scaling_xy(min=(0.9, 0.9), max=(1.1, 1.1), prob=0.5):    """    Construct a homogeneous 2D scaling matrix.    Args        min: a 2D vector containing the minimum scaling factor for X and Y.        min: a 2D vector containing The maximum scaling factor for X and Y.    Returns        the zoom matrix as 3 by 3 numpy array    """    random_prob = np.random.uniform()    if random_prob > prob:        # factor: a 2D vector for X and Y scaling        factor = random_vector(min=min, max=max)        return np.array([            [factor[0], 0, 0],            [0, factor[1], 0],            [0, 0, 1]        ])    else:        return identity_matrixdef flip_x(prob=0.8):    """    Construct a transformation randomly containing X/Y flips (or not).    Args        flip_x_chance: The chance that the result will contain a flip along the X axis.        flip_y_chance: The chance that the result will contain a flip along the Y axis.    Returns        a homogeneous 3 by 3 transformation matrix    """    random_prob = np.random.uniform()    if random_prob > prob:        # 1 - 2 * bool gives 1 for False and -1 for True.        return np.array([            [-1, 0, 0],            [0, 1, 0],            [0, 0, 1]        ])    else:        return identity_matrixdef flip_y(prob=0.8):    """    Construct a transformation randomly containing X/Y flips (or not).    Args        flip_x_chance: The chance that the result will contain a flip along the X axis.        flip_y_chance: The chance that the result will contain a flip along the Y axis.    Returns        a homogeneous 3 by 3 transformation matrix    """    random_prob = np.random.uniform()    if random_prob > prob:        # 1 - 2 * bool gives 1 for False and -1 for True.        return np.array([            [1, 0, 0],            [0, -1, 0],            [0, 0, 1]        ])    else:        return identity_matrixdef change_transform_origin(transform, center):    """    Create a new transform representing the same transformation, only with the origin of the linear part changed.    Args        transform: the transformation matrix        center: the new origin of the transformation    Returns        translate(center) * transform * translate(-center)    """    center = np.array(center)    return np.linalg.multi_dot([np.array([[1, 0, center[0]], [0, 1, center[1]], [0, 0, 1]]),                                transform,                                np.array([[1, 0, -center[0]], [0, 1, -center[1]], [0, 0, 1]])])def random_transform(        min_rotation=0,        max_rotation=0,        min_translation=(0, 0),        max_translation=(0, 0),        min_shear=0,        max_shear=0,        min_scaling=(1, 1),        max_scaling=(1, 1),):    """    Create a random transformation.    The transformation consists of the following operations in this order (from left to right):      * rotation      * translation      * shear      * scaling      * flip x (if applied)      * flip y (if applied)    Note that by default, the data generators in `keras_retinanet.preprocessing.generators` interpret the translation     as factor of the image size. So an X translation of 0.1 would translate the image by 10% of it's width.    Set `relative_translation` to `False` in the `TransformParameters` of a data generator to have it interpret    the translation directly as pixel distances instead.    Args        min_rotation:    The minimum rotation in radians for the transform as scalar.        max_rotation:    The maximum rotation in radians for the transform as scalar.        min_translation: The minimum translation for the transform as 2D column vector.        max_translation: The maximum translation for the transform as 2D column vector.        min_shear:       The minimum shear angle for the transform in radians.        max_shear:       The maximum shear angle for the transform in radians.        min_scaling:     The minimum scaling for the transform as 2D column vector.        max_scaling:     The maximum scaling for the transform as 2D column vector.    """    return np.linalg.multi_dot([        rotation(min_rotation, max_rotation),        translation_xy(min_translation, max_translation),        shear_x(min_shear, max_shear) if np.random.uniform() > 0.5 else shear_y(min_shear, max_shear),        scaling_xy(min_scaling, max_scaling),        flip_x() if np.random.uniform() > 0.5 else flip_y(),    ])def random_transform_generator(**kwargs):    """    Create a random transform generator.    The transformation consists of the following operations in this order (from left to right):      * rotation      * translation      * shear      * scaling      * flip x (if applied)      * flip y (if applied)    Note that by default, the data generators in `keras_retinanet.preprocessing.generators` interpret the translation    as factor of the image size. So an X translation of 0.1 would translate the image by 10% of it's width.    Set `relative_translation` to `False` in the `TransformParameters` of a data generator to have it interpret    the translation directly as pixel distances instead.    Args        min_rotation: The minimum rotation in radians for the transform as scalar.        max_rotation: The maximum rotation in radians for the transform as scalar.        min_translation: The minimum translation for the transform as 2D column vector.        max_translation: The maximum translation for the transform as 2D column vector.        min_shear: The minimum shear angle for the transform in radians.        max_shear: The maximum shear angle for the transform in radians.        min_scaling: The minimum scaling for the transform as 2D column vector.        max_scaling: The maximum scaling for the transform as 2D column vector.    """    while True:        yield random_transform(**kwargs)def adjust_transform_for_image(transform, image, relative_translation):    """    Adjust a transformation for a specific image.    The translation of the matrix will be scaled with the size of the image.    The linear part of the transformation will adjusted so that the origin of the transformation will be at the center of the image.    """    height, width, channels = image.shape    result = transform    # Scale the translation with the image size if specified.    if relative_translation:        result[0:2, 2] *= [width, height]    # Move the origin of transformation.    result = change_transform_origin(transform, (0.5 * width, 0.5 * height))    return resultclass TransformParameters:    """    Struct holding parameters determining how to apply a transformation to an image.    Args        fill_mode: One of: 'constant', 'nearest', 'reflect', 'wrap'        interpolation: One of: 'nearest', 'linear', 'cubic', 'area', 'lanczos4'        cval: Fill value to use with fill_mode='constant'        relative_translation:  If true (the default), interpret translation as a factor of the image size.                               If false, interpret it as absolute pixels.    """    def __init__(            self,            fill_mode='nearest',            interpolation='linear',            cval=0,            relative_translation=True,    ):        self.fill_mode = fill_mode        self.cval = cval        self.interpolation = interpolation        self.relative_translation = relative_translation    def cv_border_mode(self):        if self.fill_mode == 'constant':            return cv2.BORDER_CONSTANT        if self.fill_mode == 'nearest':            return cv2.BORDER_REPLICATE        if self.fill_mode == 'reflect':            return cv2.BORDER_REFLECT_101        if self.fill_mode == 'wrap':            return cv2.BORDER_WRAP    def cv_interpolation(self):        if self.interpolation == 'nearest':            return cv2.INTER_NEAREST        if self.interpolation == 'linear':            return cv2.INTER_LINEAR        if self.interpolation == 'cubic':            return cv2.INTER_CUBIC        if self.interpolation == 'area':            return cv2.INTER_AREA        if self.interpolation == 'lanczos4':            return cv2.INTER_LANCZOS4def apply_transform(matrix, image, params):    """    Apply a transformation to an image.    The origin of transformation is at the top left corner of the image.    The matrix is interpreted such that a point (x, y) on the original image is moved to transform * (x, y) in the generated image.    Mathematically speaking, that means that the matrix is a transformation from the transformed image space to the original image space.    Args      matrix: A homogeneous 3 by 3 matrix holding representing the transformation to apply.      image:  The image to transform.      params: The transform parameters (see TransformParameters)    """    output = cv2.warpAffine(        image,        matrix[:2, :],        dsize=(image.shape[1], image.shape[0]),        flags=params.cvInterpolation(),        borderMode=params.cvBorderMode(),        borderValue=params.cval,    )    return output################################### augmentor misc #################################def rotate(image, annotations, prob=0.5, border_value=(128, 128, 128)):    assert 'bboxes' in annotations, 'annotations should contain bboxes even if it is empty'    random_prob = np.random.uniform()    if random_prob < (1 - prob):        return image, annotations    rotate_degree = np.random.uniform(low=-45, high=45)    h, w = image.shape[:2]    # Compute the rotation matrix.    M = cv2.getRotationMatrix2D(center=(w / 2, h / 2),                                angle=rotate_degree,                                scale=1)    # Get the sine and cosine from the rotation matrix.    abs_cos_angle = np.abs(M[0, 0])    abs_sin_angle = np.abs(M[0, 1])    # Compute the new bounding dimensions of the image.    new_w = int(h * abs_sin_angle + w * abs_cos_angle)    new_h = int(h * abs_cos_angle + w * abs_sin_angle)    # Adjust the rotation matrix to take into account the translation.    M[0, 2] += new_w // 2 - w // 2    M[1, 2] += new_h // 2 - h // 2    # Rotate the image.    image = cv2.warpAffine(image, M=M, dsize=(new_w, new_h), flags=cv2.INTER_CUBIC,                           borderMode=cv2.BORDER_CONSTANT,                           borderValue=border_value)    bboxes = annotations['bboxes']    if bboxes.shape[0] != 0:        new_bboxes = []        for bbox in bboxes:            x1, y1, x2, y2 = bbox            points = M.dot([                [x1, x2, x1, x2],                [y1, y2, y2, y1],                [1, 1, 1, 1],            ])            # Extract the min and max corners again.            min_xy = np.sort(points, axis=1)[:, :2]            min_x = np.mean(min_xy[0])            min_y = np.mean(min_xy[1])            max_xy = np.sort(points, axis=1)[:, 2:]            max_x = np.mean(max_xy[0])            max_y = np.mean(max_xy[1])            new_bboxes.append([min_x, min_y, max_x, max_y])        annotations['bboxes'] = np.array(new_bboxes, dtype=np.float32)        if 'quadrangles' in annotations and annotations['quadrangles'].shape[0] != 0:            quadrangles = annotations['quadrangles']            rotated_quadrangles = []            for quadrangle in quadrangles:                quadrangle = np.concatenate([quadrangle, np.ones((4, 1))], axis=-1)                rotated_quadrangle = M.dot(quadrangle.T).T[:, :2]                quadrangle = reorder_vertexes(rotated_quadrangle)                rotated_quadrangles.append(quadrangle)            quadrangles = np.stack(rotated_quadrangles)            annotations['quadrangles'] = quadrangles            xmin = np.min(quadrangles, axis=1)[:, 0]            ymin = np.min(quadrangles, axis=1)[:, 1]            xmax = np.max(quadrangles, axis=1)[:, 0]            ymax = np.max(quadrangles, axis=1)[:, 1]            bboxes = np.stack([xmin, ymin, xmax, ymax], axis=1)            annotations['bboxes'] = bboxes    return image, annotationsdef crop(image, annotations, prob=0.5):    assert 'bboxes' in annotations, 'annotations should contain bboxes even if it is empty'    random_prob = np.random.uniform()    if random_prob < (1 - prob):        return image, annotations    h, w = image.shape[:2]    bboxes = annotations['bboxes']    if bboxes.shape[0] != 0:        min_x1, min_y1 = np.min(bboxes, axis=0)[:2]        max_x2, max_y2 = np.max(bboxes, axis=0)[2:]        random_x1 = np.random.randint(0, max(min_x1 // 2, 1))        random_y1 = np.random.randint(0, max(min_y1 // 2, 1))        random_x2 = np.random.randint(max_x2 + 1, max(min(w, max_x2 + (w - max_x2) // 2), max_x2 + 2))        random_y2 = np.random.randint(max_y2 + 1, max(min(h, max_y2 + (h - max_y2) // 2), max_y2 + 2))        image = image[random_y1:random_y2, random_x1:random_x2]        bboxes[:, [0, 2]] = bboxes[:, [0, 2]] - random_x1        bboxes[:, [1, 3]] = bboxes[:, [1, 3]] - random_y1        if 'quadrangles' in annotations and annotations['quadrangles'].shape[0] != 0:            quadrangles = annotations['quadrangles']            quadrangles[:, :, 0] = quadrangles[:, :, 0] - random_x1            quadrangles[:, :, 1] = quadrangles[:, :, 1] - random_y1    else:        random_x1 = np.random.randint(0, max(w // 8, 1))        random_y1 = np.random.randint(0, max(h // 8, 1))        random_x2 = np.random.randint(7 * w // 8, w - 1)        random_y2 = np.random.randint(7 * h // 8, h - 1)        image = image[random_y1:random_y2, random_x1:random_x2]    return image, annotationsdef flipx(image, annotations, prob=0.5):    assert 'bboxes' in annotations, 'annotations should contain bboxes even if it is empty'    random_prob = np.random.uniform()    if random_prob < (1 - prob):        return image, annotations    bboxes = annotations['bboxes']    h, w = image.shape[:2]    image = image[:, ::-1]    if bboxes.shape[0] != 0:        tmp = bboxes.copy()        bboxes[:, 0] = w - 1 - bboxes[:, 2]        bboxes[:, 2] = w - 1 - tmp[:, 0]        if 'quadrangles' in annotations and annotations['quadrangles'].shape[0] != 0:            quadrangles = annotations['quadrangles']            tmp = quadrangles.copy()            quadrangles[:, 0, 0] = w - 1 - quadrangles[:, 0, 0]            quadrangles[:, 1, 0] = w - 1 - tmp[:, 3, 0]            quadrangles[:, 1, 1] = tmp[:, 3, 1]            quadrangles[:, 2, 0] = w - 1 - quadrangles[:, 2, 0]            quadrangles[:, 3, 0] = w - 1 - tmp[:, 1, 0]            quadrangles[:, 3, 1] = tmp[:, 1, 1]    return image, annotationsdef multi_scale(image, annotations, prob=1.):    assert 'bboxes' in annotations, 'annotations should contain bboxes even if it is empty'    random_prob = np.random.uniform()    if random_prob < (1 - prob):        return image, annotations    h, w = image.shape[:2]    scale = np.random.choice(np.arange(0.7, 1.4, 0.1))    nh, nw = int(round(h * scale)), int(round(w * scale))    image = cv2.resize(image, (nw, nh), interpolation=cv2.INTER_LINEAR)    bboxes = annotations['bboxes']    if bboxes.shape[0] != 0:        annotations['bboxes'] = np.round(bboxes * scale)        if 'quadrangles' in annotations and annotations['quadrangles'].shape[0] != 0:            quadrangles = annotations['quadrangles']            annotations['quadrangles'] = np.round(quadrangles * scale)    return image, annotationsdef translate(image, annotations, prob=0.5, border_value=(128, 128, 128)):    assert 'bboxes' in annotations, 'annotations should contain bboxes even if it is empty'    random_prob = np.random.uniform()    if random_prob < (1 - prob):        return image, annotations    h, w = image.shape[:2]    bboxes = annotations['bboxes']    if bboxes.shape[0] != 0:        min_x1, min_y1 = np.min(bboxes, axis=0)[:2].astype(np.int32)        max_x2, max_y2 = np.max(bboxes, axis=0)[2:].astype(np.int32)        translation_matrix = translation_xy(min=(min(-(min_x1 // 2), 0), min(-(min_y1 // 2), 0)),                                            max=(max((w - 1 - max_x2) // 2, 1), max((h - 1 - max_y2) // 2, 1)),                                            prob=1.)    else:        translation_matrix = translation_xy(min=(min(-w // 8, 0), min(-h // 8, 0)),                                            max=(max(w // 8, 1), max(h // 8, 1)))    translation_matrix = change_transform_origin(translation_matrix, (w / 2, h / 2))    image = cv2.warpAffine(        image,        translation_matrix[:2, :],        dsize=(w, h),        flags=cv2.INTER_CUBIC,        borderMode=cv2.BORDER_CONSTANT,        borderValue=border_value,    )    if bboxes.shape[0] != 0:        new_bboxes = []        for bbox in bboxes:            x1, y1, x2, y2 = bbox            points = translation_matrix.dot([                [x1, x2, x1, x2],                [y1, y2, y2, y1],                [1, 1, 1, 1],            ])            min_x, min_y = np.min(points, axis=1)[:2]            max_x, max_y = np.max(points, axis=1)[:2]            new_bboxes.append([min_x, min_y, max_x, max_y])        annotations['bboxes'] = np.array(new_bboxes).astype(np.float32)        if 'quadrangles' in annotations and annotations['quadrangles'].shape[0] != 0:            quadrangles = annotations['quadrangles']            translated_quadrangles = []            for quadrangle in quadrangles:                quadrangle = np.concatenate([quadrangle, np.ones((4, 1))], axis=-1)                translated_quadrangle = translation_matrix.dot(quadrangle.T).T[:, :2]                quadrangle = reorder_vertexes(translated_quadrangle)                translated_quadrangles.append(quadrangle)            quadrangles = np.stack(translated_quadrangles)            annotations['quadrangles'] = quadrangles            xmin = np.min(quadrangles, axis=1)[:, 0]            ymin = np.min(quadrangles, axis=1)[:, 1]            xmax = np.max(quadrangles, axis=1)[:, 0]            ymax = np.max(quadrangles, axis=1)[:, 1]            bboxes = np.stack([xmin, ymin, xmax, ymax], axis=1)            annotations['bboxes'] = bboxes    return image, annotationsclass MiscEffect:    def __init__(self, multi_scale_prob=0.5, rotate_prob=0.05, flip_prob=0.5, crop_prob=0.5, translate_prob=0.5,                 border_value=(128, 128, 128)):        self.multi_scale_prob = multi_scale_prob        self.rotate_prob = rotate_prob        self.flip_prob = flip_prob        self.crop_prob = crop_prob        self.translate_prob = translate_prob        self.border_value = border_value    def __call__(self, image, annotations):        # image, annotations = multi_scale(image, annotations, prob=self.multi_scale_prob)        # image, annotations = rotate(image, annotations, prob=self.rotate_prob, border_value=self.border_value)        image, annotations = flipx(image, annotations, prob=self.flip_prob)        image, annotations = crop(image, annotations, prob=self.crop_prob)        image, annotations = translate(image, annotations, prob=self.translate_prob, border_value=self.border_value)        return image, annotations#################################################  augmentor color #################################def autocontrast(image, prob=0.5):    random_prob = np.random.uniform()    if random_prob > prob:        return image    image = Image.fromarray(image[..., ::-1])    image = ImageOps.autocontrast(image)    image = np.array(image)[..., ::-1]    return imagedef equalize(image, prob=0.5):    random_prob = np.random.uniform()    if random_prob > prob:        return image    image = Image.fromarray(image[..., ::-1])    image = ImageOps.equalize(image)    image = np.array(image)[..., ::-1]    return imagedef solarize(image, prob=0.5, threshold=128.):    random_prob = np.random.uniform()    if random_prob > prob:        return image    image = Image.fromarray(image[..., ::-1])    image = ImageOps.solarize(image, threshold=threshold)    image = np.array(image)[..., ::-1]    return imagedef sharpness(image, prob=0.5, min=0, max=2, factor=None):    random_prob = np.random.uniform()    if random_prob > prob:        return image    if factor is None:        # 0 模糊一点, 1 原图, 2 清晰一点        factor = np.random.uniform(min, max)    image = Image.fromarray(image[..., ::-1])    enhancer = ImageEnhance.Sharpness(image)    image = enhancer.enhance(factor=factor)    return np.array(image)[..., ::-1]def color(image, prob=0.5, min=0., max=1., factor=None):    random_prob = np.random.uniform()    if random_prob > prob:        return image    if factor is None:        # factor=0 返回黑白色, factor=1 返回原图        factor = np.random.uniform(min, max)    image = Image.fromarray(image[..., ::-1])    enhancer = ImageEnhance.Color(image)    image = enhancer.enhance(factor=factor)    return np.array(image)[..., ::-1]def contrast(image, prob=0.5, min=0.2, max=1., factor=None):    random_prob = np.random.uniform()    if random_prob > prob:        return image    if factor is None:        # factor=0 返回灰色, factor=1 返回原图        factor = np.random.uniform(min, max)    image = Image.fromarray(image[..., ::-1])    enhancer = ImageEnhance.Contrast(image)    image = enhancer.enhance(factor=factor)    return np.array(image)[..., ::-1]def brightness(image, prob=0.5, min=0.8, max=1., factor=None):    random_prob = np.random.uniform()    if random_prob > prob:        return image    if factor is None:        # factor=0 返回全黑色, factor=1 返回原图        factor = np.random.uniform(min, max)    image = Image.fromarray(image[..., ::-1])    enhancer = ImageEnhance.Brightness(image)    image = enhancer.enhance(factor=factor)    return np.array(image)[..., ::-1]class VisualEffect:    """    Struct holding parameters and applying image color transformation.    Args        solarize_threshold:        color_factor: A factor for adjusting color.        contrast_factor: A factor for adjusting contrast.        brightness_factor: A factor for adjusting brightness.        sharpness_factor: A factor for adjusting sharpness.    """    def __init__(            self,            color_factor=None,            contrast_factor=None,            brightness_factor=None,            sharpness_factor=None,            color_prob=0.5,            contrast_prob=0.5,            brightness_prob=0.5,            sharpness_prob=0.5,            autocontrast_prob=0.5,            equalize_prob=0.5,            solarize_prob=0.1,            solarize_threshold=128.,    ):        self.color_factor = color_factor        self.contrast_factor = contrast_factor        self.brightness_factor = brightness_factor        self.sharpness_factor = sharpness_factor        self.color_prob = color_prob        self.contrast_prob = contrast_prob        self.brightness_prob = brightness_prob        self.sharpness_prob = sharpness_prob        self.autocontrast_prob = autocontrast_prob        self.equalize_prob = equalize_prob        self.solarize_prob = solarize_prob        self.solarize_threshold = solarize_threshold    def __call__(self, image):        """        Apply a visual effect on the image.        Args            image: Image to adjust        """        random_enhance_id = np.random.randint(0, 4)        if random_enhance_id == 0:            image = color(image, prob=self.color_prob, factor=self.color_factor)        elif random_enhance_id == 1:            image = contrast(image, prob=self.contrast_prob, factor=self.contrast_factor)        elif random_enhance_id == 2:            image = brightness(image, prob=self.brightness_prob, factor=self.brightness_factor)        else:            image = sharpness(image, prob=self.sharpness_prob, factor=self.sharpness_factor)        random_ops_id = np.random.randint(0, 3)        if random_ops_id == 0:            image = autocontrast(image, prob=self.autocontrast_prob)        elif random_ops_id == 1:            image = equalize(image, prob=self.equalize_prob)        else:            image = solarize(image, prob=self.solarize_prob, threshold=self.solarize_threshold)        return image################################################################# main #####################def makedirs(path):    # Intended behavior: try to create the directory,    # pass if the directory exists already, fails otherwise.    # Meant for Python 2.7/3.n compatibility.    try:        os.makedirs(path)    except OSError:        if not os.path.isdir(path):            raisedef get_session():    """    Construct a modified tf session.    """    config = tf.ConfigProto()    config.gpu_options.allow_growth = True    return tf.Session(config=config)def create_callbacks(training_model, prediction_model, validation_generator, args):    """    Creates the callbacks to use during training.    Args        training_model: The model that is used for training.        prediction_model: The model that should be used for validation.        validation_generator: The generator for creating validation data.        args: parseargs args object.    Returns:        A list of callbacks used for training.    """    callbacks = []    tensorboard_callback = None    # if args.tensorboard_dir:    #     if tf.version.VERSION > '2.0.0':    #         file_writer = tf.summary.create_file_writer(args.tensorboard_dir)    #         file_writer.set_as_default()    #     tensorboard_callback = keras.callbacks.TensorBoard(    #         log_dir=args.tensorboard_dir,    #         histogram_freq=0,    #         batch_size=args.batch_size,    #         write_graph=True,    #         write_grads=False,    #         write_images=False,    #         embeddings_freq=0,    #         embeddings_layer_names=None,    #         embeddings_metadata=None    #     )    #     callbacks.append(tensorboard_callback)    if args.evaluation and validation_generator:        if args.dataset_type == 'coco':            from eval.coco import Evaluate            # use prediction model for evaluation            evaluation = Evaluate(validation_generator, prediction_model, tensorboard=tensorboard_callback)        else:            from eval.pascal import Evaluate            evaluation = Evaluate(validation_generator, prediction_model, tensorboard=tensorboard_callback)        callbacks.append(evaluation)    # save the model    # if args.snapshots:    #     # ensure directory created first; otherwise h5py will error after epoch.    #     makedirs(args.snapshot_path)    #     checkpoint = keras.callbacks.ModelCheckpoint(    #         os.path.join(    #             args.snapshot_path,    #             f'{args.dataset_type}_{{epoch:02d}}_{{loss:.4f}}_{{val_loss:.4f}}.h5' if args.compute_val_loss    #             else f'{args.dataset_type}_{{epoch:02d}}_{{loss:.4f}}.h5'    #         ),    #         verbose=1,    #         save_weights_only=True,    #         save_best_only=False,    #         monitor="val_loss",    #         # mode='max'    #     )    #     callbacks.append(checkpoint)    # callbacks.append(keras.callbacks.ReduceLROnPlateau(    #     monitor='loss',    #     factor=0.1,    #     patience=2,    #     verbose=1,    #     mode='auto',    #     min_delta=0.0001,    #     cooldown=0,    #     min_lr=0    # ))    return callbacksdef create_generators(args):    """    Create generators for training and validation.    Args        args: parseargs object containing configuration for generators.        preprocess_image: Function that preprocesses an image for the network.    """    common_args = {        'batch_size': args.batch_size,        'phi': args.phi,        'detect_text': args.detect_text,        'detect_quadrangle': args.detect_quadrangle    }    # create random transform generator for augmenting training data    if args.random_transform:        misc_effect = MiscEffect()        visual_effect = VisualEffect()    else:        misc_effect = None        visual_effect = None    if args.dataset_type == 'pascal':        from generators.pascal import PascalVocGenerator        train_generator = PascalVocGenerator(            args.pascal_path,            'train',            skip_difficult=False,            misc_effect=misc_effect,            visual_effect=visual_effect,            **common_args        )        validation_generator = PascalVocGenerator(            args.pascal_path,            'val',            skip_difficult=False,            shuffle_groups=False,            **common_args        )    elif args.dataset_type == 'csv':        from generators.csv_ import CSVGenerator        train_generator = CSVGenerator(            args.annotations_path,            args.classes_path,            misc_effect=misc_effect,            visual_effect=visual_effect,            **common_args        )        if args.val_annotations_path:            validation_generator = CSVGenerator(                args.val_annotations_path,                args.classes_path,                shuffle_groups=False,                **common_args            )        else:            validation_generator = None    elif args.dataset_type == 'coco':        # import here to prevent unnecessary dependency on cocoapi        from generators.coco import CocoGenerator        train_generator = CocoGenerator(            args.coco_path,            'train2017',            misc_effect=misc_effect,            visual_effect=visual_effect,            group_method='random',            **common_args        )        validation_generator = CocoGenerator(            args.coco_path,            'val2017',            shuffle_groups=False,            **common_args        )    elif args.dataset_type == 'wheat':        from generators.wheat import WheatGenerator        train_generator = WheatGenerator(            data_dir = args.wheat_path,#"/home/AlgorithmicGroup/yw/workshop/cloth_det/data/wheat",            label_dir = args.wheat_lable_path,            label_name = "train_part.csv",            **common_args        )        validation_generator = WheatGenerator(            data_dir = args.wheat_path,#"/home/AlgorithmicGroup/yw/workshop/cloth_det/data/wheat",            label_dir = args.wheat_lable_path,            label_name = "val.csv",            **common_args        )    else:        raise ValueError('Invalid data type received: {}'.format(args.dataset_type))    return train_generator, validation_generatordef check_args(parsed_args):    """    Function to check for inherent contradictions within parsed arguments.    For example, batch_size < num_gpus    Intended to raise errors prior to backend initialisation.    Args        parsed_args: parser.parse_args()    Returns        parsed_args    """    if parsed_args.gpu and parsed_args.batch_size < len(parsed_args.gpu.split(',')):        raise ValueError(            "Batch size ({}) must be equal to or higher than the number of GPUs ({})".format(parsed_args.batch_size,                                                                                             len(parsed_args.gpu.split(                                                                                                 ','))))    return parsed_argsdef parse_args(args):    """    Parse the arguments.    """    today = str(date.today())    parser = argparse.ArgumentParser(description='Simple training script for training a RetinaNet network.')    subparsers = parser.add_subparsers(help='Arguments for specific dataset types.', dest='dataset_type')    subparsers.required = True    wheat_parser = subparsers.add_parser('wheat')    wheat_parser.add_argument('wheat_path', help='Path to dataset directory (ie. /tmp/COCO).')    wheat_parser.add_argument('wheat_lable_path', help='Path to label directory (ie. /tmp/COCO).')    coco_parser = subparsers.add_parser('coco')    coco_parser.add_argument('coco_path', help='Path to dataset directory (ie. /tmp/COCO).')    pascal_parser = subparsers.add_parser('pascal')    pascal_parser.add_argument('pascal_path', help='Path to dataset directory (ie. /tmp/VOCdevkit).')    csv_parser = subparsers.add_parser('csv')    csv_parser.add_argument('annotations_path', help='Path to CSV file containing annotations for training.')    csv_parser.add_argument('classes_path', help='Path to a CSV file containing class label mapping.')    csv_parser.add_argument('--val-annotations-path',                            help='Path to CSV file containing annotations for validation (optional).')        parser.add_argument('--detect-quadrangle', help='If to detect quadrangle.', action='store_true', default=False)    parser.add_argument('--detect-text', help='If is text detection task.', action='store_true', default=False)    parser.add_argument('--snapshot', help='Resume training from a snapshot.')    parser.add_argument('--freeze-backbone', help='Freeze training of backbone layers.', action='store_true')    parser.add_argument('--freeze-bn', help='Freeze training of BatchNormalization layers.', action='store_true')    parser.add_argument('--weighted-bifpn', help='Use weighted BiFPN', action='store_true')    parser.add_argument('--batch-size', help='Size of the batches.', default=1, type=int)    parser.add_argument('--phi', help='Hyper parameter phi', default=0, type=int, choices=(0, 1, 2, 3, 4, 5, 6))    parser.add_argument('--gpu', help='Id of the GPU to use (as reported by nvidia-smi).')    parser.add_argument('--epochs', help='Number of epochs to train.', type=int, default=50)    parser.add_argument('--steps', help='Number of steps per epoch.', type=int, default=10000)    parser.add_argument('--snapshot-path',                        help='Path to store snapshots of models during training',                        default='checkpoints/{}'.format(today))    parser.add_argument('--tensorboard-dir', help='Log directory for Tensorboard output',                        default='logs/{}'.format(today))    parser.add_argument('--no-snapshots', help='Disable saving snapshots.', dest='snapshots', action='store_false')    parser.add_argument('--no-evaluation', help='Disable per epoch evaluation.', dest='evaluation',                        action='store_false')    parser.add_argument('--random-transform', help='Randomly transform image and annotations.', action='store_true')    parser.add_argument('--compute-val-loss', help='Compute validation loss during training', dest='compute_val_loss',                        action='store_true')    # Fit generator arguments    parser.add_argument('--multiprocessing', help='Use multiprocessing in fit_generator.', action='store_true')    parser.add_argument('--workers', help='Number of generator workers.', type=int, default=1)    parser.add_argument('--max-queue-size', help='Queue length for multiprocessing workers in fit_generator.', type=int,                        default=10)    parser.add_argument('--save_path', help='save model.')    print(vars(parser.parse_args(args)))    return check_args(parser.parse_args(args))def main(args=None):    # parse arguments    if args is None:        args = sys.argv[1:]    args = parse_args(args)    # create the generators    train_generator, validation_generator = create_generators(args)    num_classes = train_generator.num_classes()    num_anchors = train_generator.num_anchors    # optionally choose specific GPU    if args.gpu:        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu    # K.set_session(get_session())    model, prediction_model = efficientdet(args.phi,                                           num_classes=num_classes,                                           num_anchors=num_anchors,                                           weighted_bifpn=args.weighted_bifpn,                                           freeze_bn=args.freeze_bn,                                           detect_quadrangle=args.detect_quadrangle                                           )    # load pretrained weights    if args.snapshot:        if args.snapshot == 'imagenet':            model_name = 'efficientnet-b{}'.format(args.phi)            file_name = '{}_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'.format(model_name)            weights_path = os.path.join("models/", file_name)            model.load_weights(weights_path, by_name=True)        else:            print('Loading model, this may take a second...')            model.load_weights(args.snapshot, by_name=True)    # model_path = "models/my_model.h5"    # model.load_weights(model_path, by_name=True)        # freeze backbone layers    if args.freeze_backbone:        # 227, 329, 329, 374, 464, 566, 656        for i in range(1, [227, 329, 329, 374, 464, 566, 656][args.phi]):            model.layers[i].trainable = False    if args.gpu and len(args.gpu.split(',')) > 1:        model = keras.utils.multi_gpu_model(model, gpus=list(map(int, args.gpu.split(','))))    # compile model    earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')    checkpoint = ModelCheckpoint(filepath=os.path.join(args.save_path, 'my_model.h5'),                 monitor='val_loss', save_best_only=True, save_weights_only=True)    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, min_lr=1e-7)     model.compile(optimizer=Adam(lr=1e-3), loss={        'regression': smooth_l1_quad() if args.detect_quadrangle else smooth_l1(),        'classification': focal()    }, )    # create the callbacks    callbacks = create_callbacks(        model,        prediction_model,        validation_generator,        args,    )    callbacks += [earlystop,                checkpoint,                reduce_lr]    if not args.compute_val_loss:        validation_generator = None    elif args.compute_val_loss and validation_generator is None:        raise ValueError('When you have no validation data, you should not specify --compute-val-loss.')    # start training    return model.fit_generator(        generator=train_generator,        steps_per_epoch=args.steps,        initial_epoch=0,        epochs=args.epochs,        verbose=1,        callbacks=callbacks,        workers=args.workers,        use_multiprocessing=args.multiprocessing,        max_queue_size=args.max_queue_size,        validation_data=validation_generator    )if __name__ == '__main__':    main()